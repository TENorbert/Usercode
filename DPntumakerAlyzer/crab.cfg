[CRAB]
jobtype = cmssw
#scheduler = condor
scheduler = glite
#server_name = cern
#use_server=1

[CMSSW]
#lumi_mask=Cert_160404-180252_7TeV_PromptReco_Collisions11_JSON.txt
#total_number_of_lumis = -1
#lumis_per_job = 300

#runselection=123596
#increment_seeds=sourceSeed,g4SimHits
#preserve_seeds=sourceSeed,g4SimHits
#first_run=3
#generator=pythia
#skip_TFileService_output = 1
#get_edm_output = 1

### The name of ParameterSet to be used
#total_number_of_events=-1
#events_per_job =20000

lumi_mask=Cert_160404-180252_7TeV_PromptReco_Collisions11_JSON.txt
pset=dpanalysis_cfg.py
datasetpath=/Photon/Run2011B-19Nov2011-v1/AOD
#number_of_jobs = 10
output_file =Photon_2011B_AODDATA.root


[USER]
email = tambe@cern.ch
#thresholdLevel = 100
return_data = 0
copy_data = 1

#storage_element=charm.ucr.edu
#storage_port=10443 
#storage_path = /srm/v2/server?SFN=/data/bottom/cms/store/ 
#user_remote_dir = users/sckao/PAT387MC4/

#storage_element=cmssrm.fnal.gov
#storage_path=/srm/managerv2?SFN=/resilient/sckao
#user_remote_dir = MC2011

# storage to cern
storage_element = srm-cms.cern.ch
storage_path    = /srm/managerv2?SFN=/castor/cern.ch
#storage_element=srm-cms.cern.ch
#storage_path=/srm/managerv2?SFN=/castor/cern.ch/user/s/sckao/
user_remote_dir=/user/t/tambe/Photon


#local_stage_out= 0
publish_data=0

[GRID]
proxy_server = myproxy.cern.ch
virtual_organization = cms

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

